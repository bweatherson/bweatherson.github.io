{"title":"Consequences of Arrow","markdown":{"yaml":{"title":"Consequences of Arrow","date":"1/21/2026","format":{"revealjs":"default","beamer":"default"}},"headingText":"The Theorem","containsRefs":false,"markdown":"\n\n\n## Impossibility Theorem\n\n**Arrow's Impossibility Theorem** (1951) demonstrates that no voting system can simultaneously satisfy a set of seemingly reasonable conditions for democratic decision-making.\n\n## Arrow's Requirements\n\nArrow focussed on four requirements you'd like a system to have.\n\n1. **Unrestricted Domain** (U)\n2. **Weak Pareto Principle** (P)  \n3. **Independence of Irrelevant Alternatives** (I)\n4. **Non-dictatorship** (D)\n\n## The Impossibility Theorem\n\n**Arrow's Theorem**: There is no social choice function that simultaneously satisfies:\n\n- Unrestricted Domain (U)\n- Weak Pareto Principle (P)\n- Independence of Irrelevant Alternatives (I)  \n- Non-dictatorship (D)\n\n# Consequences\n\n## Democracy and Arrow\n\nYou'll often read people saying that Arrow's Theorem is a particular problem for **democratic** systems.\n\nIt seems to show that there is no system of aggregating votes that meets some really plausible conditions.\n\nSo is that bad news for voting systems?\n\n- Yes, but...\n\n## Dictatorship and Arrow\n\nLet's say that instead of democracy your preferred social model is benevolent dictatorship, where an all powerful ruler acts in the best interests of the people collectively.\n\n- Aside one: If this was a history of social thought class, we'd walk through how popular a model this was among reformers through the 19th century.\n- Aside two: For things where the government has to act although approximately zero votes will turn on how they act, this is our actual system. Think about things like the city council deciding the rules for a particular intersection.\n\n## Dictatorship and Arrow\n\nIf our dictator genuinely cares about the people, then what they do should be sensitive to their interests collectively. And that presumably means:\n\n1. They have to act no matter what those interests are (U)\n2. They should do A rather than B if it's in everyone's interests (W)\n3. Whether they do A or B should only turn on which of those two is better for the people (I)\n4. They shouldn't act just in the interests of one person (D)\n\n## Dictatorship and Arrow\n\nNote that the condition D does not just say there shouldn't be one guy making all the decisions.\n\nIt says that the decisions shouldn't be made just sensitive to what one person wants, or in the interests of one person.\n\nSo really all the conditions might be met, even for a benevolent dictator.\n\n## Markets and Arrow\n\nWell maybe you don't like dictators; I don't particularly either.\n\nPerhaps you think a market system of free trade between free people will produce a better outcome for the people collectively.\n\nThat's an interesting claim, and actually one that Arrow himself did some important work on formalising.\n\nBut we still need to define what it is for something to be a better outcome.\n\n## Markets and Arrow\n\nAnd we'll now have the same problem the benevolent dictator faced.\n\n- Our theory of better outcomes should work no matter what's good or bad for individuals (U)\n- What's better for everyone should be better overall (W)\n- Whether A or B is better overall should just turn on which of them is better for individuals (I)\n- Whether A or B is better overall should not just turn on what's better for one person (D)\n\n## Summary\n\nArrow's Theorem does raise a challenge to democratic systems.\n\nBut it raises more or less the same challenge for non-democratic systems as well.\n\nWhat it really challenges is the idea of a public good, and that's something that democrats, benevolent dictators, and free marketeers, all care about.\n\n# Two Partial Ways Out\n\n## Restrict U\n\nI won't spend much time on this, but it turns out that there are some pretty interesting results on how far you can go if you restrict U.\n\nThe most significant result concerns what are called **single-peaked preferences**.\n\n## Single Peaked Preferences\n\nImagine that there is some linear scale you can place the options on, and for every voter, the options satisfy the following condition.\n\n- The voter has a preferred spot on the scale.\n- If A is between B and that preferred spot, then the voter prefers A to B.\n- E.g., all the candidates fall on a left-right spectrum, and so do all the voters, and a voter will never prefer to move away from their preferred spot on the spectrum.\n\n## Single Peaked Preferences\n\nGiven this constraint, majority rule works. You never get Condorcet style cycles.\n\n- Is this realistic?\n- It sometimes is! If you think in advance that your voter pool meets this condition, simple majority rule is a perfectly good rule.\n- In a different class I'd work through a more precise statement of what single-peaked means, because it's actually a little more generous a condition than it looks, but we'll leave it go here unless people have particular questions.\n\n## Give Up Ordering\n\nAmartya Sen, who we'll talk more about in future lectures, argued for a while that we should give up the constraint that the output should be an ordering.\n\nIn particular, he thought that we should give up the constraint that the output should be complete.\n\n## Give Up Ordering\n\nSo let's say that we want an output to be a pair >~$\\forall$~ and =~$\\forall$~, and our rule is unanimity.\n\nIf everyone prefers A to B, then A >~$\\forall$~ B, and if everyone ranks them equally, then A =~$\\forall$~ B.\n\nWe still insist that at most one of A >~$\\forall$~ B, B >~$\\forall$~ A, and A =~$\\forall$~ B holds, but we don't insist that at least one holds.\n\n## Give Up Ordering\n\nThis rule satisfies all our constraints, except for completeness of the social ordering.\n\n- It gives a result whatever the input, satisfying U.\n- If everyone prefers A to B, so does the social ordering, satisfying W.\n- The social ordering of A and B only turns on what people think about those options, satisfying I.\n- And anyone might not get their way on A and B, satisfying D.\n\n## Give Up Ordering\n\nThe problem is that this is an incredibly weak rule.\n\n- It just says, choose Pareto dominant options.\n- It doesn't say what to do when none of them exist.\n- Moreover, dropping completeness essentially only gets you this extra rule.\n- Allan Gibbard (a long time member of the philosophy department at UM) proved that the only rule satisfying all four constraints but not completeness is unanimity among 'oligarchs', where membership of the oligarchy could be anything.\n\n# Independence of Irrelevant Alternatives\n\n## Voting Systems\n\nHere's a research topic that at one time I thought would be interesting.\n\n- Look through actual existing voting systems.\n- Since they exist, they must be possible.\n- And so they must violate one of the Arrow constraints.\n- Question: For each system, which one do they violate?\n\n## Boring Answer\n\n- They violate Independence of Irrelevant Alternatives (I).\n- They **all** violate I.\n- It wasn't an interesting research topic because that's always the answer.\n\n## IIA and Plurality\n\nWhen you see weird failures of plurality, like when two similar candidates lose because of vote splitting, it's tempting to say that the problem is that plurality voting violates I.\n\n- That can't be right on its own; all systems violate I.\n- What could be a good complaint is that plurality leads to *frequent* violations of I in *realistic* situations, but the existence of violations can't be the problem.\n\n## Is IIA Plausible?\n\nHere's one difference between IIA and real-life voting systems.\n\n- Voting systems tend to care a lot about which option a voter ranks **first**. (Plurality says this is all that matters, which is extreme, but all real life systems have this feature>0\n- The spirit behind IIA is that this shouldn't matter.\n- If I prefer A to B, that should count the same whether or not A is my **first** choice.\n\n## Should First Matter?\n\nSo one question to think about is basically, does being a voter's first choice matter, or is this just another spot on the preference ranking.\n\nI think there's a reasonable case that being first should matter.\n\n- Think about football fandom (to use a timely but non-political example).\n- It matters a lot more to most people whether their most preferred team (i.e., the team they're a fan of) wins, than whether it's their 12th or 13th favorite team that wins.\n- That's the intuition behind voting systems, and I think it's an OK one.\n\n# Numerical Measures\n\n## Preferences Only\n\nAnother way aggregation systems get around Arrow is by using numerical scales.\n\n- Amazon reviews average out numbers from 1-5.\n- Traffic planners try to minimise everyone's time spent at an intersection (conditional on the intersection being safe).\n- How does this interact with the Arrow principles?\n\n## Preferences and Numbers\n\nThe answer is that it violates one of the very first assumptions we made.\n\n- Arrow says that the aggregation system should take the preferences of the voters as an input, and return a social ordering as the output.\n- But numerical measures of how good an option is for a citizen/voter, can't be deduced from their preferences.\n\n## Preferences and Numbers\n\nIn the two tables below, Alex and Charlie are 'voters', and the numbers show how they rate (on a 1-5 scale), blickets and widgets. The left table is what they think on Monday, the right table is Tuesday.\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n|  Voter  |  Blicket  |  Widget  |\n|--------:|:---------:|:--------:|\n| Alex    |   5       |     1    |\n| Charlie |   2       |     3    |\n| Average |   3.5     |     2    |\n\n: Monday's ratings\n:::\n\n::: {.column width=\"50%\"}\n|  Voter  |  Blicket  |  Widget  |\n|--------:|:---------:|:--------:|\n| Alex    |   3       |     2    |\n| Charlie |   1       |     5    |\n| Average |   2       |   3.5    |\n\n: Tuesday's ratings\n:::\n\n::::\n\n## Preferences and Numbers\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n|  Voter  |  Blicket  |  Widget  |\n|--------:|:---------:|:--------:|\n| Alex    |   5       |     1    |\n| Charlie |   2       |     3    |\n| Average |   3.5     |     2    |\n\n: Monday's ratings\n:::\n\n::: {.column width=\"50%\"}\n|  Voter  |  Blicket  |  Widget  |\n|--------:|:---------:|:--------:|\n| Alex    |   3       |     2    |\n| Charlie |   1       |     5    |\n| Average |   2       |   3.5    |\n\n: Tuesday's ratings\n:::\n\n::::\n\n- On Monday, blickets have a higher average score than widgets.\n- On Tuesday, it's the other way around.\n- But no one's preferences changed.\n\n## Preferences and Numbers\n\nTechnically, this is a violation of I.\n\nBut more importantly, it's a violation of functionality.\n\nThe social ordering is not a function, in the mathematical sense, of the preferences of the voters.\n\nAny numerical system will be like this.\n\n## Why Not Numbers\n\nSo why isn't this the solution? Why don't we just use numerical measures of how good an option is for each person.\n\n- One reason is one we discussed in voting systems; it really doesn't work in voting because the incentives to vote 'strategically' are too high and too easy to spot.\n- But another reason comes from philosophy.\n\n## Interpersonal Utility Comparisons\n\nIf the benevolent dictator wants to use numbers not rankings, they have to generate what are called \"Interpersonal Utility Comparisons\".\n\nThe standard view in mid-century philosophy/economics/social science was that these were impossible.\n\nThe canonical argument for this is Lionel Robbins's argument in his 1938 paper \"Interpersonal Comparisons of Utility: A Comment\", which turned on the difficulty of measuring comparisons between people.\n\n## Arrow and Numbers\n\nFor the benevolent dictator, or the free market exponent, this turns out to be the big question.\n\nIf you can say not just that A is better than B for citizen C, but you can measure how much better it is, then you should use that quantity in making social decisions.\n\nIf not, you're back in Arrow's framework, and you have to think about which condition to give up.\n\n## For Next Time\n\nWe'll look at a surprising argument that sometimes the right condition to give up is the Pareto optimality condition.\n\nSome plausible looking systems of social choice end up violating it, and perhaps that's a good thing.\n","srcMarkdownNoYaml":"\n\n# The Theorem\n\n## Impossibility Theorem\n\n**Arrow's Impossibility Theorem** (1951) demonstrates that no voting system can simultaneously satisfy a set of seemingly reasonable conditions for democratic decision-making.\n\n## Arrow's Requirements\n\nArrow focussed on four requirements you'd like a system to have.\n\n1. **Unrestricted Domain** (U)\n2. **Weak Pareto Principle** (P)  \n3. **Independence of Irrelevant Alternatives** (I)\n4. **Non-dictatorship** (D)\n\n## The Impossibility Theorem\n\n**Arrow's Theorem**: There is no social choice function that simultaneously satisfies:\n\n- Unrestricted Domain (U)\n- Weak Pareto Principle (P)\n- Independence of Irrelevant Alternatives (I)  \n- Non-dictatorship (D)\n\n# Consequences\n\n## Democracy and Arrow\n\nYou'll often read people saying that Arrow's Theorem is a particular problem for **democratic** systems.\n\nIt seems to show that there is no system of aggregating votes that meets some really plausible conditions.\n\nSo is that bad news for voting systems?\n\n- Yes, but...\n\n## Dictatorship and Arrow\n\nLet's say that instead of democracy your preferred social model is benevolent dictatorship, where an all powerful ruler acts in the best interests of the people collectively.\n\n- Aside one: If this was a history of social thought class, we'd walk through how popular a model this was among reformers through the 19th century.\n- Aside two: For things where the government has to act although approximately zero votes will turn on how they act, this is our actual system. Think about things like the city council deciding the rules for a particular intersection.\n\n## Dictatorship and Arrow\n\nIf our dictator genuinely cares about the people, then what they do should be sensitive to their interests collectively. And that presumably means:\n\n1. They have to act no matter what those interests are (U)\n2. They should do A rather than B if it's in everyone's interests (W)\n3. Whether they do A or B should only turn on which of those two is better for the people (I)\n4. They shouldn't act just in the interests of one person (D)\n\n## Dictatorship and Arrow\n\nNote that the condition D does not just say there shouldn't be one guy making all the decisions.\n\nIt says that the decisions shouldn't be made just sensitive to what one person wants, or in the interests of one person.\n\nSo really all the conditions might be met, even for a benevolent dictator.\n\n## Markets and Arrow\n\nWell maybe you don't like dictators; I don't particularly either.\n\nPerhaps you think a market system of free trade between free people will produce a better outcome for the people collectively.\n\nThat's an interesting claim, and actually one that Arrow himself did some important work on formalising.\n\nBut we still need to define what it is for something to be a better outcome.\n\n## Markets and Arrow\n\nAnd we'll now have the same problem the benevolent dictator faced.\n\n- Our theory of better outcomes should work no matter what's good or bad for individuals (U)\n- What's better for everyone should be better overall (W)\n- Whether A or B is better overall should just turn on which of them is better for individuals (I)\n- Whether A or B is better overall should not just turn on what's better for one person (D)\n\n## Summary\n\nArrow's Theorem does raise a challenge to democratic systems.\n\nBut it raises more or less the same challenge for non-democratic systems as well.\n\nWhat it really challenges is the idea of a public good, and that's something that democrats, benevolent dictators, and free marketeers, all care about.\n\n# Two Partial Ways Out\n\n## Restrict U\n\nI won't spend much time on this, but it turns out that there are some pretty interesting results on how far you can go if you restrict U.\n\nThe most significant result concerns what are called **single-peaked preferences**.\n\n## Single Peaked Preferences\n\nImagine that there is some linear scale you can place the options on, and for every voter, the options satisfy the following condition.\n\n- The voter has a preferred spot on the scale.\n- If A is between B and that preferred spot, then the voter prefers A to B.\n- E.g., all the candidates fall on a left-right spectrum, and so do all the voters, and a voter will never prefer to move away from their preferred spot on the spectrum.\n\n## Single Peaked Preferences\n\nGiven this constraint, majority rule works. You never get Condorcet style cycles.\n\n- Is this realistic?\n- It sometimes is! If you think in advance that your voter pool meets this condition, simple majority rule is a perfectly good rule.\n- In a different class I'd work through a more precise statement of what single-peaked means, because it's actually a little more generous a condition than it looks, but we'll leave it go here unless people have particular questions.\n\n## Give Up Ordering\n\nAmartya Sen, who we'll talk more about in future lectures, argued for a while that we should give up the constraint that the output should be an ordering.\n\nIn particular, he thought that we should give up the constraint that the output should be complete.\n\n## Give Up Ordering\n\nSo let's say that we want an output to be a pair >~$\\forall$~ and =~$\\forall$~, and our rule is unanimity.\n\nIf everyone prefers A to B, then A >~$\\forall$~ B, and if everyone ranks them equally, then A =~$\\forall$~ B.\n\nWe still insist that at most one of A >~$\\forall$~ B, B >~$\\forall$~ A, and A =~$\\forall$~ B holds, but we don't insist that at least one holds.\n\n## Give Up Ordering\n\nThis rule satisfies all our constraints, except for completeness of the social ordering.\n\n- It gives a result whatever the input, satisfying U.\n- If everyone prefers A to B, so does the social ordering, satisfying W.\n- The social ordering of A and B only turns on what people think about those options, satisfying I.\n- And anyone might not get their way on A and B, satisfying D.\n\n## Give Up Ordering\n\nThe problem is that this is an incredibly weak rule.\n\n- It just says, choose Pareto dominant options.\n- It doesn't say what to do when none of them exist.\n- Moreover, dropping completeness essentially only gets you this extra rule.\n- Allan Gibbard (a long time member of the philosophy department at UM) proved that the only rule satisfying all four constraints but not completeness is unanimity among 'oligarchs', where membership of the oligarchy could be anything.\n\n# Independence of Irrelevant Alternatives\n\n## Voting Systems\n\nHere's a research topic that at one time I thought would be interesting.\n\n- Look through actual existing voting systems.\n- Since they exist, they must be possible.\n- And so they must violate one of the Arrow constraints.\n- Question: For each system, which one do they violate?\n\n## Boring Answer\n\n- They violate Independence of Irrelevant Alternatives (I).\n- They **all** violate I.\n- It wasn't an interesting research topic because that's always the answer.\n\n## IIA and Plurality\n\nWhen you see weird failures of plurality, like when two similar candidates lose because of vote splitting, it's tempting to say that the problem is that plurality voting violates I.\n\n- That can't be right on its own; all systems violate I.\n- What could be a good complaint is that plurality leads to *frequent* violations of I in *realistic* situations, but the existence of violations can't be the problem.\n\n## Is IIA Plausible?\n\nHere's one difference between IIA and real-life voting systems.\n\n- Voting systems tend to care a lot about which option a voter ranks **first**. (Plurality says this is all that matters, which is extreme, but all real life systems have this feature>0\n- The spirit behind IIA is that this shouldn't matter.\n- If I prefer A to B, that should count the same whether or not A is my **first** choice.\n\n## Should First Matter?\n\nSo one question to think about is basically, does being a voter's first choice matter, or is this just another spot on the preference ranking.\n\nI think there's a reasonable case that being first should matter.\n\n- Think about football fandom (to use a timely but non-political example).\n- It matters a lot more to most people whether their most preferred team (i.e., the team they're a fan of) wins, than whether it's their 12th or 13th favorite team that wins.\n- That's the intuition behind voting systems, and I think it's an OK one.\n\n# Numerical Measures\n\n## Preferences Only\n\nAnother way aggregation systems get around Arrow is by using numerical scales.\n\n- Amazon reviews average out numbers from 1-5.\n- Traffic planners try to minimise everyone's time spent at an intersection (conditional on the intersection being safe).\n- How does this interact with the Arrow principles?\n\n## Preferences and Numbers\n\nThe answer is that it violates one of the very first assumptions we made.\n\n- Arrow says that the aggregation system should take the preferences of the voters as an input, and return a social ordering as the output.\n- But numerical measures of how good an option is for a citizen/voter, can't be deduced from their preferences.\n\n## Preferences and Numbers\n\nIn the two tables below, Alex and Charlie are 'voters', and the numbers show how they rate (on a 1-5 scale), blickets and widgets. The left table is what they think on Monday, the right table is Tuesday.\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n|  Voter  |  Blicket  |  Widget  |\n|--------:|:---------:|:--------:|\n| Alex    |   5       |     1    |\n| Charlie |   2       |     3    |\n| Average |   3.5     |     2    |\n\n: Monday's ratings\n:::\n\n::: {.column width=\"50%\"}\n|  Voter  |  Blicket  |  Widget  |\n|--------:|:---------:|:--------:|\n| Alex    |   3       |     2    |\n| Charlie |   1       |     5    |\n| Average |   2       |   3.5    |\n\n: Tuesday's ratings\n:::\n\n::::\n\n## Preferences and Numbers\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n|  Voter  |  Blicket  |  Widget  |\n|--------:|:---------:|:--------:|\n| Alex    |   5       |     1    |\n| Charlie |   2       |     3    |\n| Average |   3.5     |     2    |\n\n: Monday's ratings\n:::\n\n::: {.column width=\"50%\"}\n|  Voter  |  Blicket  |  Widget  |\n|--------:|:---------:|:--------:|\n| Alex    |   3       |     2    |\n| Charlie |   1       |     5    |\n| Average |   2       |   3.5    |\n\n: Tuesday's ratings\n:::\n\n::::\n\n- On Monday, blickets have a higher average score than widgets.\n- On Tuesday, it's the other way around.\n- But no one's preferences changed.\n\n## Preferences and Numbers\n\nTechnically, this is a violation of I.\n\nBut more importantly, it's a violation of functionality.\n\nThe social ordering is not a function, in the mathematical sense, of the preferences of the voters.\n\nAny numerical system will be like this.\n\n## Why Not Numbers\n\nSo why isn't this the solution? Why don't we just use numerical measures of how good an option is for each person.\n\n- One reason is one we discussed in voting systems; it really doesn't work in voting because the incentives to vote 'strategically' are too high and too easy to spot.\n- But another reason comes from philosophy.\n\n## Interpersonal Utility Comparisons\n\nIf the benevolent dictator wants to use numbers not rankings, they have to generate what are called \"Interpersonal Utility Comparisons\".\n\nThe standard view in mid-century philosophy/economics/social science was that these were impossible.\n\nThe canonical argument for this is Lionel Robbins's argument in his 1938 paper \"Interpersonal Comparisons of Utility: A Comment\", which turned on the difficulty of measuring comparisons between people.\n\n## Arrow and Numbers\n\nFor the benevolent dictator, or the free market exponent, this turns out to be the big question.\n\nIf you can say not just that A is better than B for citizen C, but you can measure how much better it is, then you should use that quantity in making social decisions.\n\nIf not, you're back in Arrow's framework, and you have to think about which condition to give up.\n\n## For Next Time\n\nWe'll look at a surprising argument that sometimes the right condition to give up is the Pareto optimality condition.\n\nSome plausible looking systems of social choice end up violating it, and perhaps that's a good thing.\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","css":["custom_styles_css.css"],"incremental":true,"highlight-style":"github","output-file":"04.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.8.24","auto-stretch":true,"date-format":"full","theme":["default","custom_theme_scss.scss"],"slideNumber":"c/t","showSlideNumber":"all","hash-type":"number","previewLinks":"auto","chalkboard":false,"multiplex":false,"footer":"PHIL 342 | University of Michigan","logo":"logo.png","transition":"slide","backgroundTransition":"fade","smaller":false,"scrollable":true,"navigationMode":"default","controls":false,"menu":true,"title":"Consequences of Arrow","date":"1/21/2026"}},"beamer":{"identifier":{"display-name":"Beamer","target-format":"beamer","base-format":"beamer"},"execute":{"fig-width":10,"fig-height":7,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"beamer","slide-level":2,"toc":false,"number-sections":false,"highlight-style":"github","output-file":"04.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"block-headings":true,"date-format":"full","theme":"metropolis","colortheme":"default","fonttheme":"structurebold","section-titles":false,"header-includes":["\\usepackage{fontspec}\n\\setmainfont{Arial}\n\\setmonofont[Scale=0.8]{Fira Mono}\n\\definecolor{primary}{RGB}{0, 102, 153}\n\\definecolor{secondary}{RGB}{102, 153, 204}\n\\setbeamercolor{frametitle}{fg=primary}\n\\setbeamercolor{title}{fg=primary}\n\\setbeamertemplate{footline}[frame number]\n\\setbeamertemplate{navigation symbols}{}\n"],"title":"Consequences of Arrow","date":"1/21/2026"},"classoption":["notheorems"]}},"projectFormats":["revealjs","beamer"]}